# 进程
* 父进程创建子进程。父进程可以在产生子进程后继续执行，也可以等待子进程运行完成后再继续执行

## 实现一个新进程 
* 通过 join 可以避免主进程直接退出，导出子进程驻留在操作系统中。

```python
import multiprocessing

def foo(i):
    print ("called function in process: {}".format(i))
    return

if __name__ == '__main__':
    jobs = []
    for i in range(5):
        p = multiprocessing.Process(target=foo, args=(i,))
        jobs.append(p)
        p.start()
        p.join()

```
* 子进程在创建的时候会导入包含目标函数的脚本，为了预防无限递归调用:
    * 需要将进程的调用放在 __main__ 函数中
    * target 执行函数也放到其他模块中引入

    ```python
    import multiprocessing
    import target_func

    if __name__ == '__main__':
        jobs = []
        for i in range(5):
            p = multiprocessing.Process(target=target_func, args=(i,))
            jobs.append(p)
            p.start()
            p.join()

    ```   
* 杀死子进程(terminate)，检查子进程状态(is_alive)，查看子进程退出码(exitcode)

```
def foo():
    print ("Starting function")
    time.sleep(0.1)
    print ("Finished function")


if __name__ == '__main__':
   p = multiprocessing.Process(target=foo)
   print ("Process berore excution: {}".format(p.is_alive()))
   p.start()
   print ("Process runing: {}".format(p.is_alive()))
   p.terminate()
   time.sleep(0.1)
   print ("Process terminate: {}".format(p.is_alive()))
   p.join()
   print ("Process joined: {}".format(p.is_alive()))
   print ("Process exit code: {}".format(p.exitcode))
```
* 在子类中使用进程, 重写run方法，该方法是子进程的入口

```
import multiprocessing

class MyProcess(multiprocessing.Process):

    def __init__(self):
        super(MyProcess, self).__init__()

    def run(self):
        print ("called run method in process: {}".format(self.name))


if __name__ == '__main__':
    jobs = []
    for i in range(5):
        p = MyProcess()
        jobs.append(p)
        p.start()
    [p.join() for p in jobs]
```
## 进程间通信
### queue

```
import multiprocessing
import random
import time

class Producer(multiprocessing.Process):
    def __init__(self, queue):
        super(Producer,self).__init__()
        self.queue = queue

    def run(self):
        for i in range(10):
            item = random.randint(0, 256)
            self.queue.put(item)
            print("Process Producer : item %d appended to queue %s" % (item, self.name))
            time.sleep(1)

class Consumer(multiprocessing.Process):
    def __init__(self, queue):
        multiprocessing.Process.__init__(self)
        self.queue = queue

    def run(self):
        while True:
            if self.queue.empty():
                print("the queue is empty")
                break
            else:
                time.sleep(2)
                item = self.queue.get()
                print('Process Consumer : item %d popped from by %s \n' % (item, self.name))
                time.sleep(1)

if __name__ == '__main__':
    queue = multiprocessing.Queue()
    process_producer = Producer(queue)
    process_consumer = Consumer(queue)
    process_producer.start()
    process_consumer.start()
    process_producer.join()
    process_consumer.join()
```
### pipe 双向管道
* 定义了输入管道 pipe_1 和 输出管道 pipe_2 。输入管道发送数据，输出管道接收消息并处理

```
def create_items(pipe):
    output_pipe,_ = pipe 
    for item in range(10):
        output_pipe.send(item)
    output_pipe.close()

def multiply_items(pip_1,pip_2):
    close, input_pipe = pipe_1
    close.close()
    output_pipe,_ = pip_2
    try:
        while True:
            item = input_pipe.recv()
            output_pipe.send(item*item)
    except EOFError as e:
        output_pipe.close()


if __name__ == '__main__':
    #send
    pipe_1 = multiprocessing.Pipe(True)
    process_pipe_1 = multiprocessing.Process(target=create_items, args=(pipe_1,))
    process_pipe_1.start()
    #recv
    pipe_2 = multiprocessing.Pipe(True)
    process_pipe_2 = multiprocessing.Process(target=multiply_items, args=(pipe_1,pipe_2))
    process_pipe_2.start()
    pipe_1[0].close()
    pipe_2[0].close()

    try:
        while True:
            print (pipe_2[1].recv())
    except EOFError:
        print ("End")
```
## 进程同步
* 线程同步原语,都可以用于进程同步 Lock, Event,Rloc,Condition,Semaphore

### 使用 __Barrier__ (屏障) 同步进程
* __屏障__ : 将程序分成几个阶段，适用于有些进程必须在某些特定进程之后执行。处于屏障（Barrier）之后的代码不能在处于障碍之前的代码并行。
* 进程1 和进程 2 进程 3 各自运行，当达到屏障的时候，等待所有进程的屏障 wait完成后在继续执行

```
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# ylgongPw @ 2020-02-21 13:03:22
from __future__ import unicode_literals
from __future__ import absolute_import

import multiprocessing
from multiprocessing import Barrier, Lock, Process
from time import time
from datetime import datetime

def test_with_barrier(synchronizer, serializer):
    name = multiprocessing.current_process().name
    synchronizer.wait()
    now = time()

    with serializer:
        print ("process {} -----> {}".format(name,datetime.fromtimestamp(now)))



if __name__ == '__main__':
    synchronizer = Barrier(3) #管理的进程数
    serializer = Lock()
    Process(name="p1 - test_with_barrier", target=test_with_barrier,args=(synchronizer,serializer)).start()
    Process(name="p2 - test_with_barrier", target=test_with_barrier,args=(synchronizer,serializer)).start()
    Process(name="p3 - test_with_barrier", target=test_with_barrier,args=(synchronizer,serializer)).start()
```


